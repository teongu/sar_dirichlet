pred <- data.frame(left = Minv %*% as.matrix(Xbeta1),
right = Minv %*% as.matrix(Xbeta2),
other = Minv %*% as.matrix(Xbeta3))
pred_final <- lr_inv(pred)
cos_similarity <- function(x1, x2) {
mean(sapply(seq_len(nrow(x1)), function(i) {
sum(x1[i,] * x2[i,]) / (sqrt(sum(x1[i,]^2)) * sqrt(sum(x2[i,]^2)))
}))
}
rmse_aitchison <- function(x1, x2) {
n <- nrow(x1)
D <- ncol(x1)
log_x1 <- log(x1)
log_x2 <- log(x2)
row_rmse <- numeric(n)
for (i in 1:n) {
# Log-ratio matrices for row i
v1 <- as.numeric(log_x1[i, ])
v2 <- as.numeric(log_x2[i, ])
diff1 <- outer(v1, v1, "-")
diff2 <- outer(v2, v2, "-")
delta <- diff1 - diff2
squared <- delta^2
row_rmse[i] <- sqrt(sum(squared) / (2 * D))
}
return(mean(row_rmse))
}
n = 207
mse_values <- numeric()
for (i in 1:ncol(Y_occitanie)) {
# Compute MSE for the current column
mse_values[i] <- MSE(pred_final[, i], Y_occitanie[, i])
}
# RMSE_A
rmse_aitchison(pred_final, Y_occitanie)
W_mat <- as.matrix(read.csv("occitanie/W_elections_5nn.csv", sep=" ", header=FALSE))
#W_mat <- as.matrix(read.csv("occitanie/W_elections_distance.csv", sep=",", header=FALSE))
W <- mat2listw(W_mat, style="W")
X_scaled <- as.data.frame(lapply(X_occitanie, normalize))
# we drop columns age_65 and foreign that cause aliased variables error
X_scaled <- subset(X_scaled, select = -c(`age_65`, `foreign`))
lr_Y <- lr(Y_occitanie)
lm_list <- list()
for (i in seq_along(lr_Y)) {
# Fit a linear model for response variable i using the features in X
lm_model <- lagsarlm(lr_Y[, i] ~ . - 1, data = X_scaled, listw=W)
# Store the linear model in the list
lm_list[[i]] <- lm_model
}
Xbeta1 <- as.matrix(X_scaled) %*% as.matrix(lm_list[[1]]$coefficients)
Xbeta2 <- as.matrix(X_scaled) %*% as.matrix(lm_list[[2]]$coefficients)
Xbeta3 <- as.matrix(X_scaled) %*% as.matrix(lm_list[[3]]$coefficients)
rho = mean(c(lm_list[[1]]$rho, lm_list[[2]]$rho, lm_list[[3]]$rho))
Minv = solve( diag(nrow(W_mat)) - rho*W_mat )
pred <- data.frame(left = Minv %*% as.matrix(Xbeta1),
right = Minv %*% as.matrix(Xbeta2),
other = Minv %*% as.matrix(Xbeta3))
pred_final <- lr_inv(pred)
cos_similarity <- function(x1, x2) {
mean(sapply(seq_len(nrow(x1)), function(i) {
sum(x1[i,] * x2[i,]) / (sqrt(sum(x1[i,]^2)) * sqrt(sum(x2[i,]^2)))
}))
}
n = 207
mse_values <- numeric()
for (i in 1:ncol(Y_occitanie)) {
# Compute MSE for the current column
mse_values[i] <- MSE(pred_final[, i], Y_occitanie[, i])
}
## contiguity with 5 neighbours
# R2 = 0.4141665
mean(diag(cor(pred_final, Y_occitanie) ^ 2))
# RMSE = 0.1145348
sqrt(mean(mse_values))
# cross-entropy = -1.075672
sum(Y_occitanie * log(pred_final)) / n
# cos similarity = 0.9511475
cos_similarity(Y_occitanie, pred_final)
# RMSE_A = 0.549894
rmse_aitchison(pred_final, Y_occitanie)
# Adjusted R squared
n = 1000
k = 8
R = 0.9309
1 - (1-R)*(n-1)/(n-k-1)
k = 9
R = 0.9335
1 - (1-R)*(n-1)/(n-k-1)
k = 8
R = 0.8311
1 - (1-R)*(n-1)/(n-k-1)
R = 0.001
1 - (1-R)*(n-1)/(n-k-1)
R = 0.2073
1 - (1-R)*(n-1)/(n-k-1)
k = 9
R = 0.9408
1 - (1-R)*(n-1)/(n-k-1)
R = 0.9011
1 - (1-R)*(n-1)/(n-k-1)
a = (n-1)/(n-k-1)
R = 0.0026
a = (n-1)/(n-k-1)
R*a
k = 8
R = 0.0025
a = (n-1)/(n-k-1)
1 - (1-R)*a
R*a
R = 0.0001
a = (n-1)/(n-k-1)
R*a
# Adjusted R squared
n = 39
k = 5 #order 1, non-spatial
R = 0.589
a = (n-1)/(n-k-1)
1 - (1-R)*a
stdR = 0.015
stdR*a
k = 6 #order 1, spatial
R = 0.632
a = (n-1)/(n-k-1)
1 - (1-R)*a
stdR = 0.015
stdR*a
R = 0.589
1 - (1-R)*a
a = (n-1)/(n-k)
1 - (1-R)*a
stdR = 0.015
stdR*a
R = 0.632
a = (n-1)/(n-k)
1 - (1-R)*a
R = 0.589
k = 5 #order 1, non-spatial
R = 0.589
a = (n-1)/(n-k)
1 - (1-R)*a
stdR = 0.015
stdR*a
k = 7 #order 2, non-spatial
R = 0.678
a = (n-1)/(n-k)
1 - (1-R)*a
stdR = 0.014
stdR*a
k = 8 #order 2, spatial
R = 0.694
a = (n-1)/(n-k)
1 - (1-R)*a
stdR = 0.014
stdR*a
R = 0.686
a = (n-1)/(n-k)
1 - (1-R)*a
stdR = 0.015
stdR*a
k = 4 #order 1, non-spatial
R = 0.628
a = (n-1)/(n-k)
1 - (1-R)*a
stdR = 0.013
stdR*a
k = 5 #order 1, spatial
R = 0.667
a = (n-1)/(n-k)
1 - (1-R)*a
stdR = 0.014
stdR*a
R = 0.633
a = (n-1)/(n-k)
1 - (1-R)*a
stdR = 0.013
stdR*a
k = 6 #order 2, non-spatial
R = 0.689
a = (n-1)/(n-k)
1 - (1-R)*a
stdR = 0.013
stdR*a
k = 7 #order 2, spatial
R = 0.705
a = (n-1)/(n-k)
1 - (1-R)*a
stdR = 0.013
stdR*a
R = 0.705
a = (n-1)/(n-k)
1 - (1-R)*a
stdR = 0.016
stdR*a
k = 2 #order 1, non-spatial
k = 3 #order 1, spatial
k = 3 #order 1, spatial
R = 0.675
a = (n-1)/(n-k)
1 - (1-R)*a
stdR = 0.265
stdR*a
R = 0.598
a = (n-1)/(n-k)
1 - (1-R)*a
stdR = 0.278
stdR*a
k = 4 #order 2, spatial
R = 0.671
a = (n-1)/(n-k)
1 - (1-R)*a
stdR = 0.271
stdR*a
R = 0.730
a = (n-1)/(n-k)
1 - (1-R)*a
# Adjusted R squared for Dirichlet
n = 207
k = 76 #non-spatial
R = 0.487
a = (n-1)/(n-k)
1 - (1-R)*a
k = 77 #spatial
R = 0.582
a = (n-1)/(n-k)
1 - (1-R)*a
R = 0.602
a = (n-1)/(n-k)
1 - (1-R)*a
# Adjusted R squared for multinomial
n = 207
k = 75 #non-spatial
R = 0.494
a = (n-1)/(n-k)
1 - (1-R)*a
k = 76 #spatial
R = 0.589
a = (n-1)/(n-k)
1 - (1-R)*a
R = 0.608
a = (n-1)/(n-k)
1 - (1-R)*a
Y_occitanie
X_scaled
dim(X_scaled)
ncol(X_scaled)
# Adjusted R squared for logit normal
n = 207
k = 18 #spatial
R = 0.414
a = (n-1)/(n-k)
1 - (1-R)*a
R = 0.414
a = (n-1)/(n-k)
1 - (1-R)*a
k = 19 #spatial
R = 0.414
a = (n-1)/(n-k)
1 - (1-R)*a
R = 0.434
a = (n-1)/(n-k)
1 - (1-R)*a
# for the synthetic datasets
# Adjusted R squared for logit normal
n = 1000
k = 8 #non-spatial
R = 0.9955
a = (n-1)/(n-k)
1 - (1-R)*a
k = 9 #spatial
R = 0.999
a = (n-1)/(n-k)
1 - (1-R)*a
k = 8 #non-spatial
R = 0.8399
a = (n-1)/(n-k)
1 - (1-R)*a
stdR = 0.0001
stdR*a
k = 9 #spatial
a = (n-1)/(n-k)
stdR = 0.0002
stdR*a
R = 0.9958
a = (n-1)/(n-k)
1 - (1-R)*a
k = 8 #non-spatial
R = 0.1207
a = (n-1)/(n-k)
1 - (1-R)*a
stdR = 0.0063
stdR*a
k = 9 #spatial
R = 0.8891
a = (n-1)/(n-k)
1 - (1-R)*a
stdR = 0.0093
stdR*a
# Adjusted Rsquared for the synthetic datasets
n = 1000
k = 6 #non-spatial
R = 0.9956
a = (n-1)/(n-k)
1 - (1-R)*a
R = 0.865
a = (n-1)/(n-k)
1 - (1-R)*a
stdR = 0.0001
stdR*a
R = 0.2382
a = (n-1)/(n-k)
1 - (1-R)*a
stdR = 0.0027
stdR*a
k = 7 #spatial
R = 0.999
a = (n-1)/(n-k)
1 - (1-R)*a
# RMSE_A = 8.225174
rmse_aitchison(pred_final, Y)
library(readr)
library(spdep)
library(spatialreg)
library(MLmetrics)
lr <- function(x) {
log(x / rowMeans(x))
}
lr_inv <- function(x) {
exp(x) / rowSums(exp(x))
}
X_scaled <- read.csv("maupiti_X.csv", sep=",", header=FALSE)
Y <- read.csv("maupiti_Y.csv", sep=",", header=FALSE)
W_mat <- as.matrix(read.csv("maupiti_W_no_zeros.csv", sep=",", header=FALSE))
W <- mat2listw(W_mat, style="W")
lr_Y <- lr(Y)
lm_list <- list()
for (i in seq_along(lr_Y)) {
# Fit a linear model for response variable i using the features in X
lm_model <- lagsarlm(lr_Y[, i] ~ . - 1, data = X_scaled, listw=W)
# Store the linear model in the list
lm_list[[i]] <- lm_model
}
Xbeta1 <- as.matrix(X_scaled) %*% as.matrix(lm_list[[1]]$coefficients)
Xbeta2 <- as.matrix(X_scaled) %*% as.matrix(lm_list[[2]]$coefficients)
Xbeta3 <- as.matrix(X_scaled) %*% as.matrix(lm_list[[3]]$coefficients)
Xbeta4 <- as.matrix(X_scaled) %*% as.matrix(lm_list[[4]]$coefficients)
rho = mean(c(lm_list[[1]]$rho, lm_list[[2]]$rho, lm_list[[3]]$rho, lm_list[[4]]$rho))
Minv = solve( diag(nrow(W_mat)) - rho*W_mat )
pred <- data.frame(c1 = Minv %*% as.matrix(Xbeta1),
c2 = Minv %*% as.matrix(Xbeta2),
c3 = Minv %*% as.matrix(Xbeta3),
c4 = Minv %*% as.matrix(Xbeta4))
pred_final <- lr_inv(pred)
cos_similarity <- function(x1, x2) {
mean(sapply(seq_len(nrow(x1)), function(i) {
sum(x1[i,] * x2[i,]) / (sqrt(sum(x1[i,]^2)) * sqrt(sum(x2[i,]^2)))
}))
}
rmse_aitchison <- function(x1, x2) {
n <- nrow(x1)
D <- ncol(x1)
log_x1 <- log(x1)
log_x2 <- log(x2)
row_rmse <- numeric(n)
for (i in 1:n) {
# Log-ratio matrices for row i
v1 <- as.numeric(log_x1[i, ])
v2 <- as.numeric(log_x2[i, ])
diff1 <- outer(v1, v1, "-")
diff2 <- outer(v2, v2, "-")
delta <- diff1 - diff2
squared <- delta^2
row_rmse[i] <- sqrt(sum(squared) / (2 * D))
}
return(mean(row_rmse))
}
n = 2301
mse_values <- numeric()
for (i in 1:ncol(Y)) {
# Compute MSE for the current column
mse_values[i] <- MSE(pred_final[, i], Y[, i])
}
# R2 = 0.4147603
mean(diag(cor(pred_final, Y) ^ 2))
# RMSE = 0.3003778
sqrt(mean(mse_values))
# cross-entropy = -1.667296
sum(Y * log(pred_final)) / n
# cos similarity = 0.8031862
cos_similarity(Y, pred_final)
# RMSE_A = 8.225174
rmse_aitchison(pred_final, Y)
dim(W)
dim(W_mat)
W
View(W)
library(readr)
library(spdep)
library(spatialreg)
library(MLmetrics)
lr <- function(x) {
log(x / rowMeans(x))
}
lr_inv <- function(x) {
exp(x) / rowSums(exp(x))
}
X_scaled <- read.csv("maupiti_X.csv", sep=",", header=FALSE)
Y <- read.csv("maupiti_Y.csv", sep=",", header=FALSE)
W_mat <- as.matrix(read.csv("maupiti_W_no_zeros.csv", sep=",", header=FALSE))
W <- mat2listw(W_mat, style="W")
unique(W[1,:])
W[1,:]
W[1,]
W[1]
W
W_mat[1]
W_mat[1,:]
W_mat[1,]
unique(W_mat[1,])
lr_Y <- lr(Y)
lm_list <- list()
for (i in seq_along(lr_Y)) {
# Fit a linear model for response variable i using the features in X
lm_model <- lagsarlm(lr_Y[, i] ~ . - 1, data = X_scaled, listw=W)
# Store the linear model in the list
lm_list[[i]] <- lm_model
}
for (i in 1:2301){
if (unique(W_mat[i,])==1){
W_mat[i,] <- W_mat[i,]/2301
}
}
unique(W_mat[i,])
(unique(W_mat[i,])==c(1))
length(unique(W_mat[i,]))
for (i in 1:2301){
unique_values <- unique(W_mat[i,])
if ( (length(unique_values)==1) & (unique_values==1) ){
W_mat[i,] <- W_mat[i,]/2301
}
}
(length(unique_values)==1) & (unique_values==1)
for (i in 1:2301){
unique_values <- unique(W_mat[i,])
if (length(unique_values)==1){
if (unique_values==1){
W_mat[i,] <- W_mat[i,]/2301
}
}
}
View(W_mat)
W <- mat2listw(W_mat, style="W")
lr_Y <- lr(Y)
lm_list <- list()
for (i in seq_along(lr_Y)) {
# Fit a linear model for response variable i using the features in X
lm_model <- lagsarlm(lr_Y[, i] ~ . - 1, data = X_scaled, listw=W)
# Store the linear model in the list
lm_list[[i]] <- lm_model
}
Xbeta1 <- as.matrix(X_scaled) %*% as.matrix(lm_list[[1]]$coefficients)
Xbeta2 <- as.matrix(X_scaled) %*% as.matrix(lm_list[[2]]$coefficients)
Xbeta3 <- as.matrix(X_scaled) %*% as.matrix(lm_list[[3]]$coefficients)
Xbeta4 <- as.matrix(X_scaled) %*% as.matrix(lm_list[[4]]$coefficients)
rho = mean(c(lm_list[[1]]$rho, lm_list[[2]]$rho, lm_list[[3]]$rho, lm_list[[4]]$rho))
Minv = solve( diag(nrow(W_mat)) - rho*W_mat )
pred <- data.frame(c1 = Minv %*% as.matrix(Xbeta1),
c2 = Minv %*% as.matrix(Xbeta2),
c3 = Minv %*% as.matrix(Xbeta3),
c4 = Minv %*% as.matrix(Xbeta4))
pred_final <- lr_inv(pred)
cos_similarity <- function(x1, x2) {
mean(sapply(seq_len(nrow(x1)), function(i) {
sum(x1[i,] * x2[i,]) / (sqrt(sum(x1[i,]^2)) * sqrt(sum(x2[i,]^2)))
}))
}
rmse_aitchison <- function(x1, x2) {
n <- nrow(x1)
D <- ncol(x1)
log_x1 <- log(x1)
log_x2 <- log(x2)
row_rmse <- numeric(n)
for (i in 1:n) {
# Log-ratio matrices for row i
v1 <- as.numeric(log_x1[i, ])
v2 <- as.numeric(log_x2[i, ])
diff1 <- outer(v1, v1, "-")
diff2 <- outer(v2, v2, "-")
delta <- diff1 - diff2
squared <- delta^2
row_rmse[i] <- sqrt(sum(squared) / (2 * D))
}
return(mean(row_rmse))
}
n = 2301
mse_values <- numeric()
for (i in 1:ncol(Y)) {
# Compute MSE for the current column
mse_values[i] <- MSE(pred_final[, i], Y[, i])
}
# R2 = 0.4147603
mean(diag(cor(pred_final, Y) ^ 2))
# RMSE = 0.3003778
sqrt(mean(mse_values))
# cross-entropy = -1.667296
sum(Y * log(pred_final)) / n
# cos similarity = 0.8031862
cos_similarity(Y, pred_final)
# RMSE_A = 8.225174
rmse_aitchison(pred_final, Y)
# AIC ?
pred_final[pred_final < 10e-05] <- 10e-05
rmse_aitchison(pred_final, Y)
