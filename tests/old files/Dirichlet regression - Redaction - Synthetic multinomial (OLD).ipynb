{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from texttable import Texttable\n",
    "import latextable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../sar_dirichlet')\n",
    "import dirichlet_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from func_test import cos_similarity, create_features_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.1'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With two features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 2\n",
    "n_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(21)\n",
    "\n",
    "beta = np.array([[0.  , -1.6 , 1.],\n",
    "                 [0.  , 1.8, -1.4],\n",
    "                 [0.  , 1.4, -1.1 ]])\n",
    "\n",
    "gamma_var = np.round(np.random.normal(size=(n_features)),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_repeat = 100\n",
    "#list_n_samples = [50,200,1000]\n",
    "list_n_samples = [50,200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples=200\n",
    "rho=0.5\n",
    "#np.random.seed(11)\n",
    "cov_mat = np.array([[1., 0.1], [0.1, 1.]])\n",
    "X,Z,W = create_features_matrices(n_samples,n_features,choice_W='random_distance',nneighbors=10, cov_mat=cov_mat)\n",
    "Z = np.ones(n_samples).reshape(-1,1)\n",
    "list_n_i = np.random.randint(1, high=100, size=n_samples)\n",
    "M = np.identity(n_samples) - rho*W\n",
    "mu = dirichlet_regression.compute_mu_spatial(X, beta, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.array([np.random.multinomial(list_n_i[i],mu[i])/list_n_i[i] for i in range(n_samples)])\n",
    "Y = (Y*(n_samples-1)+1/n_classes)/n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_test = dirichlet_regression.dirichletRegressor(spatial=False)\n",
    "reg_test.fit(X, Y, parametrization='alternative', Z=Z, fit_intercept=False, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6904\n",
      "0.9701\n",
      "0.5427\n",
      "0.1139\n"
     ]
    }
   ],
   "source": [
    "print(np.round(r2_score(Y,reg_test.mu),4))\n",
    "print(np.round(cos_similarity(Y,reg_test.mu),4))\n",
    "print(np.round(-(1/n_samples)*np.sum(Y*np.log(reg_test.mu)),4))\n",
    "print(np.round(mean_squared_error(Y,reg_test.mu,squared=False),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_test = dirichlet_regression.dirichletRegressor(spatial=False)\n",
    "reg_test.fit(X, Y, parametrization='alternative', Z=Z, fit_intercept=False, verbose=0, loss='crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8016\n",
      "0.9787\n",
      "0.4994\n",
      "0.0892\n"
     ]
    }
   ],
   "source": [
    "print(np.round(r2_score(Y,reg_test.mu),4))\n",
    "print(np.round(cos_similarity(Y,reg_test.mu),4))\n",
    "print(np.round(-(1/n_samples)*np.sum(Y*np.log(reg_test.mu)),4))\n",
    "print(np.round(mean_squared_error(Y,reg_test.mu,squared=False),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_test = dirichlet_regression.dirichletRegressor(spatial=False)\n",
    "reg_test.fit(X, Y, parametrization='alternative', Z=Z, fit_intercept=False, verbose=0, loss='crossentropy', size_samples=list_n_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7955\n",
      "0.9781\n",
      "0.5001\n",
      "0.0903\n"
     ]
    }
   ],
   "source": [
    "print(np.round(r2_score(Y,reg_test.mu),4))\n",
    "print(np.round(cos_similarity(Y,reg_test.mu),4))\n",
    "print(np.round(-(1/n_samples)*np.sum(Y*np.log(reg_test.mu)),4))\n",
    "print(np.round(mean_squared_error(Y,reg_test.mu,squared=False),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_test = dirichlet_regression.dirichletRegressor(spatial=True)\n",
    "reg_test.fit(X, Y, parametrization='alternative', Z=Z, W=W, fit_intercept=False, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0871204  -0.01669151]\n",
      " [-0.0875131   0.03574297]\n",
      " [-0.06662853  0.02900188]]\n",
      "0.5006343124747678\n"
     ]
    }
   ],
   "source": [
    "print(reg_test.beta-beta[:,1:])\n",
    "print(reg_test.rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99962\n",
      "0.99997\n",
      "0.47482\n",
      "0.00336\n"
     ]
    }
   ],
   "source": [
    "print(np.round(r2_score(Y,reg_test.mu),5))\n",
    "print(np.round(cos_similarity(Y,reg_test.mu),5))\n",
    "print(np.round(-(1/n_samples)*np.sum(Y*np.log(reg_test.mu)),5))\n",
    "print(np.round(mean_squared_error(Y,reg_test.mu,squared=False),5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_test = dirichlet_regression.dirichletRegressor(spatial=True)\n",
    "reg_test.fit(X, Y, parametrization='alternative', Z=Z, W=W, fit_intercept=False, verbose=0, loss='crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.11989243 -0.01780403]\n",
      " [-0.12151223  0.04141683]\n",
      " [-0.09275043  0.0334047 ]]\n",
      "0.5008757547010351\n"
     ]
    }
   ],
   "source": [
    "print(reg_test.beta-beta[:,1:])\n",
    "print(reg_test.rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99939\n",
      "0.99996\n",
      "0.4748\n",
      "0.00423\n"
     ]
    }
   ],
   "source": [
    "print(np.round(r2_score(Y,reg_test.mu),5))\n",
    "print(np.round(cos_similarity(Y,reg_test.mu),5))\n",
    "print(np.round(-(1/n_samples)*np.sum(Y*np.log(reg_test.mu)),5))\n",
    "print(np.round(mean_squared_error(Y,reg_test.mu,squared=False),5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_test = dirichlet_regression.dirichletRegressor(spatial=True)\n",
    "reg_test.fit(X, Y, parametrization='alternative', Z=Z, W=W, fit_intercept=False, verbose=0, loss='crossentropy', size_samples=list_n_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.13179459 -0.02504934]\n",
      " [-0.12533287  0.04683481]\n",
      " [-0.0974142   0.03753615]]\n",
      "0.5033170308840984\n"
     ]
    }
   ],
   "source": [
    "print(reg_test.beta-beta[:,1:])\n",
    "print(reg_test.rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99933\n",
      "0.99995\n",
      "0.47481\n",
      "0.00449\n"
     ]
    }
   ],
   "source": [
    "print(np.round(r2_score(Y,reg_test.mu),5))\n",
    "print(np.round(cos_similarity(Y,reg_test.mu),5))\n",
    "print(np.round(-(1/n_samples)*np.sum(Y*np.log(reg_test.mu)),5))\n",
    "print(np.round(mean_squared_error(Y,reg_test.mu,squared=False),5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rho=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tnguyen001\\AppData\\Roaming\\Python\\Python38\\site-packages\\scipy\\sparse\\linalg\\dsolve\\linsolve.py:198: MatrixRankWarning: Matrix is exactly singular\n",
      "  warn(\"Matrix is exactly singular\", MatrixRankWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 26min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "list_solutions_spatial = []\n",
    "list_solutions_no_spatial = []\n",
    "list_solutions_ce_spatial = []\n",
    "list_solutions_ce_no_spatial = []\n",
    "list_r2_spatial, list_r2_no_spatial, list_r2_ce_spatial, list_r2_ce_no_spatial = [], [], [], []\n",
    "list_rmse_spatial, list_rmse_no_spatial, list_rmse_ce_spatial, list_rmse_ce_no_spatial = [], [], [], []\n",
    "list_crossentropy_spatial, list_crossentropy_no_spatial, list_crossentropy_ce_spatial, list_crossentropy_ce_no_spatial = [], [], [], []\n",
    "list_similarity_spatial, list_similarity_no_spatial, list_similarity_ce_spatial, list_similarity_ce_no_spatial = [], [], [], []\n",
    "\n",
    "\n",
    "seed=0\n",
    "\n",
    "for i in range(len(list_n_samples)):\n",
    "    n_samples = list_n_samples[i]\n",
    "    \n",
    "    true_params = np.concatenate([beta.flatten(),gamma_var, [rho]])\n",
    "    \n",
    "    solutions_spatial_temp = []\n",
    "    solutions_no_spatial_temp = []\n",
    "    solutions_ce_spatial_temp = []\n",
    "    solutions_ce_no_spatial_temp = []\n",
    "    temp_r2_spatial, temp_r2_no_spatial, temp_r2_ce_spatial, temp_r2_ce_no_spatial = [], [], [], []\n",
    "    temp_rmse_spatial, temp_rmse_no_spatial, temp_rmse_ce_spatial, temp_rmse_ce_no_spatial = [], [], [], []\n",
    "    temp_crossentropy_spatial, temp_crossentropy_no_spatial, temp_crossentropy_ce_spatial, temp_crossentropy_ce_no_spatial = [], [], [], []\n",
    "    temp_similarity_spatial, temp_similarity_no_spatial, temp_similarity_ce_spatial, temp_similarity_ce_no_spatial = [], [], [], []\n",
    "    for _ in range(n_repeat):\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "        X,Z,W = create_features_matrices(n_samples,n_features,choice_W='random_distance',nneighbors=10)\n",
    "        Z[:,0] = 1\n",
    "        #les n_i ne devraient pas bouger, il faut les fixer comme pour les betas\n",
    "        list_n_i = np.random.randint(100, high=10000, size=n_samples)\n",
    "        M = np.identity(n_samples) - rho*W\n",
    "        mu = dirichlet_regression.compute_mu_spatial(X, beta, M)\n",
    "        Y = np.array([np.random.multinomial(list_n_i[i],mu[i])/list_n_i[i] for i in range(n_samples)])\n",
    "        Y = (Y*(n_samples-1)+1/n_classes)/n_samples\n",
    "\n",
    "        try:\n",
    "            reg_spatial = dirichlet_regression.dirichletRegressor(spatial=True)\n",
    "            reg_spatial.fit(X, Y, parametrization='alternative', Z=Z, W=W, fit_intercept=False, verbose=0)\n",
    "            solutions_spatial_temp.append(np.concatenate([reg_spatial.beta.flatten(),reg_spatial.gamma,[reg_spatial.rho]]))\n",
    "            temp_r2_spatial.append(r2_score(Y,reg_spatial.mu))\n",
    "            temp_rmse_spatial.append(mean_squared_error(Y,reg_spatial.mu,squared=False))\n",
    "            temp_similarity_spatial.append(cos_similarity(Y,reg_spatial.mu))\n",
    "            temp_crossentropy_spatial.append(-(1/n_samples)*np.sum(Y*np.log(reg_spatial.mu)))\n",
    "            \n",
    "            reg_no_spatial = dirichlet_regression.dirichletRegressor(spatial=False)\n",
    "            reg_no_spatial.fit(X, Y, parametrization='alternative', Z=Z, fit_intercept=False, verbose=0)\n",
    "            solutions_no_spatial_temp.append(np.concatenate([reg_no_spatial.beta.flatten(),reg_no_spatial.gamma]))\n",
    "            temp_r2_no_spatial.append(r2_score(Y,reg_no_spatial.mu))\n",
    "            temp_rmse_no_spatial.append(mean_squared_error(Y,reg_no_spatial.mu,squared=False))\n",
    "            temp_similarity_no_spatial.append(cos_similarity(Y,reg_no_spatial.mu))\n",
    "            temp_crossentropy_no_spatial.append(-(1/n_samples)*np.sum(Y*np.log(reg_no_spatial.mu)))\n",
    "            \n",
    "            reg_spatial_ce = dirichlet_regression.dirichletRegressor(spatial=True)\n",
    "            reg_spatial_ce.fit(X, Y, loss='crossentropy', W=W, fit_intercept=False, verbose=0)\n",
    "            solutions_ce_spatial_temp.append(np.concatenate([reg_spatial_ce.beta.flatten(),[reg_spatial_ce.rho]]))\n",
    "            temp_r2_ce_spatial.append(r2_score(Y,reg_spatial_ce.mu))\n",
    "            temp_rmse_ce_spatial.append(mean_squared_error(Y,reg_spatial_ce.mu,squared=False))\n",
    "            temp_similarity_ce_spatial.append(cos_similarity(Y,reg_spatial_ce.mu))\n",
    "            temp_crossentropy_ce_spatial.append(-(1/n_samples)*np.sum(Y*np.log(reg_spatial_ce.mu)))\n",
    "            \n",
    "            reg_no_spatial_ce = dirichlet_regression.dirichletRegressor(spatial=False)\n",
    "            reg_no_spatial_ce.fit(X, Y, loss='crossentropy', fit_intercept=False, verbose=0)\n",
    "            solutions_ce_no_spatial_temp.append(reg_no_spatial_ce.beta.flatten())\n",
    "            temp_r2_ce_no_spatial.append(r2_score(Y,reg_no_spatial_ce.mu))\n",
    "            temp_rmse_ce_no_spatial.append(mean_squared_error(Y,reg_no_spatial_ce.mu,squared=False))\n",
    "            temp_similarity_ce_no_spatial.append(cos_similarity(Y,reg_no_spatial_ce.mu))\n",
    "            temp_crossentropy_ce_no_spatial.append(-(1/n_samples)*np.sum(Y*np.log(reg_no_spatial_ce.mu)))\n",
    "            \n",
    "        except RuntimeError:\n",
    "            print(\"Factor is exactly singular\")\n",
    "        except np.linalg.LinAlgError:\n",
    "            print(\"Singular matrix\")\n",
    "        \n",
    "        seed+=1\n",
    "    list_solutions_spatial.append(solutions_spatial_temp)\n",
    "    list_solutions_no_spatial.append(solutions_no_spatial_temp)\n",
    "    list_solutions_ce_spatial.append(solutions_ce_spatial_temp)\n",
    "    list_solutions_ce_no_spatial.append(solutions_ce_no_spatial_temp)\n",
    "    \n",
    "    list_r2_spatial.append(temp_r2_spatial)\n",
    "    list_r2_no_spatial.append(temp_r2_no_spatial)\n",
    "    list_r2_ce_spatial.append(temp_r2_ce_spatial)\n",
    "    list_r2_ce_no_spatial.append(temp_r2_ce_no_spatial)\n",
    "    list_rmse_spatial.append(temp_rmse_spatial)\n",
    "    list_rmse_no_spatial.append(temp_rmse_no_spatial)\n",
    "    list_rmse_ce_spatial.append(temp_rmse_ce_spatial)\n",
    "    list_rmse_ce_no_spatial.append(temp_rmse_ce_no_spatial)\n",
    "    list_crossentropy_spatial.append(temp_crossentropy_spatial)\n",
    "    list_crossentropy_no_spatial.append(temp_crossentropy_no_spatial)\n",
    "    list_crossentropy_ce_spatial.append(temp_crossentropy_ce_spatial)\n",
    "    list_crossentropy_ce_no_spatial.append(temp_crossentropy_ce_no_spatial)\n",
    "    list_similarity_spatial.append(temp_similarity_spatial)\n",
    "    list_similarity_no_spatial.append(temp_similarity_no_spatial)\n",
    "    list_similarity_ce_spatial.append(temp_similarity_ce_spatial)\n",
    "    list_similarity_ce_no_spatial.append(temp_similarity_ce_no_spatial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9996458716729916\n",
      "0.9996515560160816\n",
      "0.9995252281059591\n",
      "0.9995252284079568\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(list_similarity_spatial[2]))\n",
    "print(np.mean(list_similarity_ce_spatial[2]))\n",
    "print(np.mean(list_similarity_no_spatial[2]))\n",
    "print(np.mean(list_similarity_ce_no_spatial[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0022120233365543\n",
      "1.0022034740708814\n",
      "1.0023710892857196\n",
      "1.0023710800572112\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(list_crossentropy_spatial[2]))\n",
    "print(np.mean(list_crossentropy_ce_spatial[2]))\n",
    "print(np.mean(list_crossentropy_no_spatial[2]))\n",
    "print(np.mean(list_crossentropy_ce_no_spatial[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_params_effective = np.concatenate([beta[:,1:].flatten(),gamma_var, [rho]])\n",
    "true_params_effective_no_spatial = np.concatenate([beta[:,1:].flatten(),gamma_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('Data Dirichlet/solutions_spatial_rho01_multinomial.npy',list_solutions_spatial)\n",
    "np.save('Data Dirichlet/solutions_no_spatial_rho01_multinomial.npy',list_solutions_no_spatial)\n",
    "np.save('Data Dirichlet/solutions_ce_spatial_rho01_multinomial.npy',list_solutions_ce_spatial)\n",
    "np.save('Data Dirichlet/solutions_ce_no_spatial_rho01_multinomial.npy',list_solutions_ce_no_spatial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('Data Dirichlet/r2_spatial_rho01_multinomial.npy',list_r2_spatial)\n",
    "np.save('Data Dirichlet/r2_no_spatial_rho01_multinomial.npy',list_r2_no_spatial)\n",
    "np.save('Data Dirichlet/r2_ce_spatial_rho01_multinomial.npy',list_r2_ce_spatial)\n",
    "np.save('Data Dirichlet/r2_ce_no_spatial_rho01_multinomial.npy',list_r2_ce_no_spatial)\n",
    "np.save('Data Dirichlet/rmse_spatial_rho01_multinomial.npy',list_rmse_spatial)\n",
    "np.save('Data Dirichlet/rmse_no_spatial_rho01_multinomial.npy',list_rmse_no_spatial)\n",
    "np.save('Data Dirichlet/rmse_ce_spatial_rho01_multinomial.npy',list_rmse_ce_spatial)\n",
    "np.save('Data Dirichlet/rmse_ce_no_spatial_rho01_multinomial.npy',list_rmse_ce_no_spatial)\n",
    "np.save('Data Dirichlet/crossentropy_spatial_rho01_multinomial.npy',list_crossentropy_spatial)\n",
    "np.save('Data Dirichlet/crossentropy_no_spatial_rho01_multinomial.npy',list_crossentropy_no_spatial)\n",
    "np.save('Data Dirichlet/crossentropy_ce_spatial_rho01_multinomial.npy',list_crossentropy_ce_spatial)\n",
    "np.save('Data Dirichlet/crossentropy_ce_no_spatial_rho01_multinomial.npy',list_crossentropy_ce_no_spatial)\n",
    "np.save('Data Dirichlet/similarity_spatial_rho01_multinomial.npy',list_similarity_spatial)\n",
    "np.save('Data Dirichlet/similarity_no_spatial_rho01_multinomial.npy',list_similarity_no_spatial)\n",
    "np.save('Data Dirichlet/similarity_ce_spatial_rho01_multinomial.npy',list_similarity_ce_spatial)\n",
    "np.save('Data Dirichlet/similarity_ce_no_spatial_rho01_multinomial.npy',list_similarity_ce_no_spatial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_solutions_spatial = np.load('Data Dirichlet/solutions_spatial_rho01_multinomial.npy')\n",
    "list_solutions_no_spatial = np.load('Data Dirichlet/solutions_no_spatial_rho01_multinomial.npy')\n",
    "list_solutions_ce_spatial = np.load('Data Dirichlet/solutions_ce_spatial_rho01_multinomial.npy')\n",
    "list_solutions_ce_no_spatial = np.load('Data Dirichlet/solutions_ce_no_spatial_rho01_multinomial.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.6 ,  1.  ,  1.8 , -1.4 ,  1.4 , -1.1 , -0.05, -0.11,  0.1 ])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_params_effective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04112585, -0.05425365, -0.04252704,  0.0409255 , -0.03349975,\n",
       "        0.03788746])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([sol_i[:-2] - true_params_effective_no_spatial[:-2] for sol_i in list_solutions_no_spatial[0]],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0416002 , -0.05313316, -0.04251055,  0.04169962, -0.03423354,\n",
       "        0.03566908])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([sol_i - true_params_effective_no_spatial[:-2] for sol_i in list_solutions_ce_no_spatial[0]],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rho=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_repeat = 10\n",
    "#list_n_samples = [50,200,1000]\n",
    "list_n_samples = [50,200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tnguyen001\\AppData\\Roaming\\Python\\Python38\\site-packages\\scipy\\sparse\\linalg\\dsolve\\linsolve.py:198: MatrixRankWarning: Matrix is exactly singular\n",
      "  warn(\"Matrix is exactly singular\", MatrixRankWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "list_solutions_spatial = []\n",
    "list_solutions_no_spatial = []\n",
    "list_solutions_ce_spatial = []\n",
    "list_solutions_ce_no_spatial = []\n",
    "list_solutions_multinomial_spatial = []\n",
    "list_r2_spatial, list_r2_no_spatial, list_r2_ce_spatial, list_r2_ce_no_spatial, list_r2_multinomial_spatial = [], [], [], [], []\n",
    "list_rmse_spatial, list_rmse_no_spatial, list_rmse_ce_spatial, list_rmse_ce_no_spatial, list_rmse_multinomial_spatial = [], [], [], [], []\n",
    "list_crossentropy_spatial, list_crossentropy_no_spatial, list_crossentropy_ce_spatial, list_crossentropy_ce_no_spatial, list_crossentropy_multinomial_spatial = [], [], [], [], []\n",
    "list_similarity_spatial, list_similarity_no_spatial, list_similarity_ce_spatial, list_similarity_ce_no_spatial, list_similarity_multinomial_spatial = [], [], [], [], []\n",
    "\n",
    "\n",
    "seed=1\n",
    "\n",
    "for i in range(len(list_n_samples)):\n",
    "    n_samples = list_n_samples[i]\n",
    "    \n",
    "    true_params = np.concatenate([beta.flatten(),gamma_var, [rho]])\n",
    "    \n",
    "    solutions_spatial_temp = []\n",
    "    solutions_no_spatial_temp = []\n",
    "    solutions_ce_spatial_temp = []\n",
    "    solutions_ce_no_spatial_temp = []\n",
    "    solutions_multinomial_spatial_temp = []\n",
    "    temp_r2_spatial, temp_r2_no_spatial, temp_r2_ce_spatial, temp_r2_ce_no_spatial, temp_r2_multinomial_spatial = [], [], [], [], []\n",
    "    temp_rmse_spatial, temp_rmse_no_spatial, temp_rmse_ce_spatial, temp_rmse_ce_no_spatial, temp_rmse_multinomial_spatial = [], [], [], [], []\n",
    "    temp_crossentropy_spatial, temp_crossentropy_no_spatial, temp_crossentropy_ce_spatial, temp_crossentropy_ce_no_spatial, temp_crossentropy_multinomial_spatial = [], [], [], [], []\n",
    "    temp_similarity_spatial, temp_similarity_no_spatial, temp_similarity_ce_spatial, temp_similarity_ce_no_spatial, temp_similarity_multinomial_spatial = [], [], [], [], []\n",
    "    \n",
    "    #les n_i ne devraient pas bouger, il faut les fixer comme pour les betas\n",
    "    list_n_i = np.random.randint(1000, high=100000, size=n_samples)\n",
    "    for _ in range(n_repeat):\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "        X,Z,W = create_features_matrices(n_samples,n_features,choice_W='random_distance',nneighbors=10)\n",
    "        Z = np.ones(n_samples).reshape(-1,1)\n",
    "        M = np.identity(n_samples) - rho*W\n",
    "        mu = dirichlet_regression.compute_mu_spatial(X, beta, M)\n",
    "        \n",
    "        Y = np.array([np.random.multinomial(list_n_i[i],mu[i])/list_n_i[i] for i in range(n_samples)])\n",
    "        Y = (Y*(n_samples-1)+1/n_classes)/n_samples\n",
    "\n",
    "        try:\n",
    "            reg_spatial = dirichlet_regression.dirichletRegressor(spatial=True, maxfun=10000)\n",
    "            reg_spatial.fit(X, Y, parametrization='alternative', Z=Z, W=W, fit_intercept=False, verbose=0)\n",
    "            solutions_spatial_temp.append(np.concatenate([reg_spatial.beta.flatten(),reg_spatial.gamma,[reg_spatial.rho]]))\n",
    "            temp_r2_spatial.append(r2_score(Y,reg_spatial.mu))\n",
    "            temp_rmse_spatial.append(mean_squared_error(Y,reg_spatial.mu,squared=False))\n",
    "            temp_similarity_spatial.append(cos_similarity(Y,reg_spatial.mu))\n",
    "            temp_crossentropy_spatial.append(-(1/n_samples)*np.sum(Y*np.log(reg_spatial.mu)))\n",
    "            \n",
    "            reg_no_spatial = dirichlet_regression.dirichletRegressor(spatial=False, maxfun=10000)\n",
    "            reg_no_spatial.fit(X, Y, parametrization='alternative', Z=Z, fit_intercept=False, verbose=0)\n",
    "            solutions_no_spatial_temp.append(np.concatenate([reg_no_spatial.beta.flatten(),reg_no_spatial.gamma]))\n",
    "            temp_r2_no_spatial.append(r2_score(Y,reg_no_spatial.mu))\n",
    "            temp_rmse_no_spatial.append(mean_squared_error(Y,reg_no_spatial.mu,squared=False))\n",
    "            temp_similarity_no_spatial.append(cos_similarity(Y,reg_no_spatial.mu))\n",
    "            temp_crossentropy_no_spatial.append(-(1/n_samples)*np.sum(Y*np.log(reg_no_spatial.mu)))\n",
    "            \n",
    "            reg_spatial_ce = dirichlet_regression.dirichletRegressor(spatial=True, maxfun=10000)\n",
    "            reg_spatial_ce.fit(X, Y, loss='crossentropy', W=W, fit_intercept=False, verbose=0)\n",
    "            solutions_ce_spatial_temp.append(np.concatenate([reg_spatial_ce.beta.flatten(),[reg_spatial_ce.rho]]))\n",
    "            temp_r2_ce_spatial.append(r2_score(Y,reg_spatial_ce.mu))\n",
    "            temp_rmse_ce_spatial.append(mean_squared_error(Y,reg_spatial_ce.mu,squared=False))\n",
    "            temp_similarity_ce_spatial.append(cos_similarity(Y,reg_spatial_ce.mu))\n",
    "            temp_crossentropy_ce_spatial.append(-(1/n_samples)*np.sum(Y*np.log(reg_spatial_ce.mu)))\n",
    "            \n",
    "            reg_no_spatial_ce = dirichlet_regression.dirichletRegressor(spatial=False, maxfun=10000)\n",
    "            reg_no_spatial_ce.fit(X, Y, loss='crossentropy', fit_intercept=False, verbose=0)\n",
    "            solutions_ce_no_spatial_temp.append(reg_no_spatial_ce.beta.flatten())\n",
    "            temp_r2_ce_no_spatial.append(r2_score(Y,reg_no_spatial_ce.mu))\n",
    "            temp_rmse_ce_no_spatial.append(mean_squared_error(Y,reg_no_spatial_ce.mu,squared=False))\n",
    "            temp_similarity_ce_no_spatial.append(cos_similarity(Y,reg_no_spatial_ce.mu))\n",
    "            temp_crossentropy_ce_no_spatial.append(-(1/n_samples)*np.sum(Y*np.log(reg_no_spatial_ce.mu)))\n",
    "            \n",
    "            reg_multinomial = dirichlet_regression.dirichletRegressor(spatial=True, maxfun=10000)\n",
    "            reg_multinomial.fit(X, Y, loss='crossentropy', W=W, fit_intercept=False, verbose=0, size_samples=list_n_i)\n",
    "            solutions_multinomial_spatial_temp.append(reg_multinomial.beta.flatten())\n",
    "            temp_r2_multinomial_spatial.append(r2_score(Y,reg_multinomial.mu))\n",
    "            temp_rmse_multinomial_spatial.append(mean_squared_error(Y,reg_multinomial.mu,squared=False))\n",
    "            temp_similarity_multinomial_spatial.append(cos_similarity(Y,reg_multinomial.mu))\n",
    "            temp_crossentropy_multinomial_spatial.append(-(1/n_samples)*np.sum(Y*np.log(reg_multinomial.mu)))\n",
    "            \n",
    "        except RuntimeError:\n",
    "            print(\"Factor is exactly singular\")\n",
    "        except np.linalg.LinAlgError:\n",
    "            print(\"Singular matrix\")\n",
    "        \n",
    "        seed+=1\n",
    "    list_solutions_spatial.append(solutions_spatial_temp)\n",
    "    list_solutions_no_spatial.append(solutions_no_spatial_temp)\n",
    "    list_solutions_ce_spatial.append(solutions_ce_spatial_temp)\n",
    "    list_solutions_ce_no_spatial.append(solutions_ce_no_spatial_temp)\n",
    "    list_solutions_multinomial_spatial.append(solutions_multinomial_spatial_temp)\n",
    "    \n",
    "    list_r2_spatial.append(temp_r2_spatial)\n",
    "    list_r2_no_spatial.append(temp_r2_no_spatial)\n",
    "    list_r2_ce_spatial.append(temp_r2_ce_spatial)\n",
    "    list_r2_ce_no_spatial.append(temp_r2_ce_no_spatial)\n",
    "    list_r2_multinomial_spatial.append(temp_r2_multinomial_spatial)\n",
    "    list_rmse_spatial.append(temp_rmse_spatial)\n",
    "    list_rmse_no_spatial.append(temp_rmse_no_spatial)\n",
    "    list_rmse_ce_spatial.append(temp_rmse_ce_spatial)\n",
    "    list_rmse_ce_no_spatial.append(temp_rmse_ce_no_spatial)\n",
    "    list_rmse_multinomial_spatial.append(temp_rmse_multinomial_spatial)\n",
    "    list_crossentropy_spatial.append(temp_crossentropy_spatial)\n",
    "    list_crossentropy_no_spatial.append(temp_crossentropy_no_spatial)\n",
    "    list_crossentropy_ce_spatial.append(temp_crossentropy_ce_spatial)\n",
    "    list_crossentropy_ce_no_spatial.append(temp_crossentropy_ce_no_spatial)\n",
    "    list_crossentropy_multinomial_spatial.append(temp_crossentropy_multinomial_spatial)\n",
    "    list_similarity_spatial.append(temp_similarity_spatial)\n",
    "    list_similarity_no_spatial.append(temp_similarity_no_spatial)\n",
    "    list_similarity_ce_spatial.append(temp_similarity_ce_spatial)\n",
    "    list_similarity_ce_no_spatial.append(temp_similarity_ce_no_spatial)\n",
    "    list_similarity_multinomial_spatial.append(temp_similarity_multinomial_spatial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999651597177928\n",
      "0.9999409857089283\n",
      "0.9999382392351275\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(list_similarity_spatial[1]))\n",
    "print(np.mean(list_similarity_ce_spatial[1]))\n",
    "print(np.mean(list_similarity_multinomial_spatial[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4557490893521389\n",
      "0.4557247983441735\n",
      "0.45572840388428626\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(list_crossentropy_spatial[1]))\n",
    "print(np.mean(list_crossentropy_ce_spatial[1]))\n",
    "print(np.mean(list_crossentropy_multinomial_spatial[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9995520274054134\n",
      "0.9992383342699215\n",
      "0.999199432865167\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(list_r2_spatial[1]))\n",
    "print(np.mean(list_r2_ce_spatial[1]))\n",
    "print(np.mean(list_r2_multinomial_spatial[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
